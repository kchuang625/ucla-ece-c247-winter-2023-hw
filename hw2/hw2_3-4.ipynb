{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0606f639",
   "metadata": {},
   "source": [
    "### 3. (30 points) Softmax classifier gradient\n",
    "***\n",
    "+ (1) Derive the log-likelihood\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathcal{L}&=\\log\\prod_{i=1}^m\\Pr\\big( y^{(i)}|\\mathbf{x}^{(i)},\\theta \\big)\n",
    "=\\log\\prod_{i=1}^m\\text{softmax}_{y^{(i)}}(\\mathbf{x}^{(i)})\\\\\n",
    "&=\\log\\prod_{i=1}^m\\frac{\\exp(a_{y^{(i)}}(\\mathbf{x}^{(i)}))}{\\sum_{k=1}^c\\exp(a_k(\\mathbf{x}^{(i)}))}\\\\\n",
    "&=\\sum_{i=1}^m \\big( a_{y^{(i)}}(\\mathbf{x}^{(i)}) - \\log\\sum_{k=1}^c\\exp(a_k(\\mathbf{x}^{(i)})) \\big)\\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "+ (2) Derive its gradient\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\nabla_{\\tilde{\\mathbf{w}}_j}\\mathcal{L}\n",
    "&=\\sum_{i=1}^m \\big( \\tilde{\\mathbf{x}}^{(i)}\\mathbb{1}_{\\{j=y^{(i)}\\}} \n",
    "- \\frac{\\exp(a_{j}(\\mathbf{x}^{(i)}))}{\\sum_{k=1}^c\\exp(a_k(\\mathbf{x}^{(i)}))} \\cdot \\tilde{\\mathbf{x}}^{(i)} \\big) \\\\\n",
    "&=\\sum_{i=1}^m \\big(\\mathbb{1}_{\\{j=y^{(i)}\\}} - \\text{softmax}_j(\\mathbf{x}^{(i)})\\big)\\cdot\\tilde{\\mathbf{x}}^{(i)}\n",
    "\\end{aligned}\n",
    "$$\n",
    "$$\n",
    "\\Rightarrow \\nabla_{\\mathbf{w}_j}\\mathcal{L}=\\sum_{i=1}^m \\big(\\mathbb{1}_{\\{j=y^{(i)}\\}} - \\text{softmax}_j(\\mathbf{x}^{(i)})\\big) \\cdot \\mathbf{x}^{(i)},\n",
    "\\nabla_{b_j}\\mathcal{L}=\\sum_{i=1}^m \\big(\\mathbb{1}_{\\{j=y^{(i)}\\}} - \\text{softmax}_j(\\mathbf{x}^{(i)})\\big)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd13b177",
   "metadata": {},
   "source": [
    "### 4. (10 points) Hinge loss gradient\n",
    "***\n",
    "+ Let $\\tilde{\\mathbf{x}}=\\begin{bmatrix}\\mathbf{x}\\\\1\\end{bmatrix},\\tilde{\\mathbf{w}}=\\begin{bmatrix}\\mathbf{w}\\\\b\\end{bmatrix}$, we have\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\nabla_{\\tilde{\\mathbf{w}}}\\mathcal{L}\n",
    "&=\\frac{1}{K}\\sum_{i=1}^K \\nabla_{\\tilde{\\mathbf{w}}}\\max(0, 1-y^{(i)}\\tilde{\\mathbf{w}}^T\\tilde{\\mathbf{x}}^{(i)})\\\\\n",
    "&=\\frac{1}{K}\\sum_{i=1}^K -y^{(i)}\\tilde{\\mathbf{x}}^{(i)}\\mathbb{1}_{\\{y^{(i)}\\tilde{\\mathbf{w}}^T\\tilde{\\mathbf{x}}^{(i)}<1\\}}\n",
    "\\end{aligned}\n",
    "$$\n",
    "$$\n",
    "\\Rightarrow \\nabla_{\\mathbf{w}}\\mathcal{L}=\\frac{1}{K}\\sum_{i=1}^K -y^{(i)}\\mathbf{x}^{(i)}\\mathbb{1}_{\\{y^{(i)}\\tilde{\\mathbf{w}}^T\\tilde{\\mathbf{x}}^{(i)}<1\\}},\n",
    "\\nabla_{b}\\mathcal{L}=\\frac{1}{K}\\sum_{i=1}^K -y^{(i)}\\mathbb{1}_{\\{y^{(i)}\\tilde{\\mathbf{w}}^T\\tilde{\\mathbf{x}}^{(i)}<1\\}}\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
